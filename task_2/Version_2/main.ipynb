{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "import sklearn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\"train_features.csv\").sort_values(by='pid')\n",
    "test = pd.read_csv(\"test_features.csv\")\n",
    "train_labels = pd.read_csv(\"train_labels.csv\").sort_values(by='pid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get rid of Hgb, HCO3, ABPd, and Bilirubin_direct from the training and test data !\n",
    "\n",
    "# train_features.drop('Bilirubin_direct', axis=1, inplace=True)\n",
    "# train_features.drop('HCO3', axis=1, inplace=True)\n",
    "# train_features.drop('Hgb', axis=1, inplace=True)\n",
    "# train_features.drop('ABPd', axis=1, inplace=True)\n",
    "\n",
    "# test.drop('Bilirubin_direct', axis=1, inplace=True)\n",
    "# test.drop('HCO3', axis=1, inplace=True)\n",
    "# test.drop('Hgb', axis=1, inplace=True)\n",
    "# test.drop('ABPd', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now look at the correlation heatmap of the train data \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def corr_check(data):\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    fig, ax = plt.subplots(figsize=(40,35))         # Sample figsize in inches\n",
    "    sns.heatmap(data.corr(), linewidths=.5, ax=ax, annot= True)\n",
    "    plt.show()\n",
    "    \n",
    "raw_data = pd.concat([train_features, train_labels['LABEL_Sepsis']], axis=1, sort=False)\n",
    "#corr_check(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_KNN(df):\n",
    "    imputed_df = pd.DataFrame(columns=df.columns)\n",
    "    imp = sklearn.impute.KNNImputer(n_neighbors=1)\n",
    "    for pid in tqdm(np.unique(df['pid'].values)):\n",
    "        temp_df = df.loc[df['pid'] == pid]\n",
    "        temp_df2 = temp_df.dropna(axis = 'columns', how = 'all')\n",
    "        imp.fit(temp_df2)\n",
    "        temp_df2 = pd.DataFrame(data = imp.transform(temp_df2), columns = temp_df2.columns)\n",
    "        for key in temp_df.columns:\n",
    "            if temp_df[key].isna().all():\n",
    "                temp_df2[key] = np.nan\n",
    "        imputed_df = imputed_df.append(temp_df2, sort = True)\n",
    "    imputed_df.reindex(columns = df.columns)\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Imputing training data\")\n",
    "\n",
    "train_features_imp = impute_KNN(train_features)\n",
    "\n",
    "print (\"###############################\")\n",
    "\n",
    "print(\"Imputing test data\")\n",
    "\n",
    "\n",
    "test_imputed = impute_KNN(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mode(df):\n",
    "    for column in df.columns:\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_imp = impute_mode(train_features_imp)\n",
    "test = impute_mode(test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we would like to have one patient per row. Each feature has a time-series observations and we will extract standard set of features.\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "\n",
    "def feature_extract(column, df):\n",
    "    \n",
    "    minimum = df[column].min()\n",
    "    maximum = df[column].max()\n",
    "    mean = np.float32(df[column].mean())\n",
    "    standard_deviation = np.float32(df[column].std())\n",
    "    median = np.float(df[column].median())\n",
    "    skewness = np.float(df[column].skew())\n",
    "    kurtosis = np.float(df[column].kurtosis())\n",
    "    \n",
    "    return minimum, maximum, mean, standard_deviation, median, skewness, kurtosis\n",
    "\n",
    "# Let's create a dictionary to store new features\n",
    "\n",
    "def new_df(df):\n",
    "\n",
    "    new_df = {}\n",
    "\n",
    "    for column in df.columns[(df.columns!='pid') & (df.columns!='Age') & (df.columns!='Time')]:  # We don't really need pid, Age and Time \n",
    "        new_df[column+'_minimum'] = []\n",
    "        new_df[column+'_maximum'] = []\n",
    "        new_df[column+'_mean'] = []\n",
    "        new_df[column+'_std'] = [] \n",
    "        new_df[column+'_median'] = []\n",
    "        new_df[column+'_skewness'] = []\n",
    "        new_df[column+'_kurtosis'] = []\n",
    "\n",
    "    new_df['pid'] = []\n",
    "    new_df['Age'] = []\n",
    "\n",
    "    # Create a new dataframe with new extracted features\n",
    "\n",
    "    for pid in tqdm(df.pid.unique()):\n",
    "\n",
    "        for column in df.columns[(df.columns!='pid') & (df.columns!='Age') & (df.columns!='Time')]:\n",
    "            #print(column)\n",
    "            minimum, maximum, mean, standard_deviation, median, skewness, kurtosis = feature_extract(column, df[df.pid == pid])    \n",
    "            #print(minimum, maximum, mean, standard_deviation)\n",
    "            new_df[column+'_minimum'].append(minimum)\n",
    "            new_df[column+'_maximum'].append(maximum)\n",
    "            new_df[column+'_mean'].append(mean)\n",
    "            new_df[column+'_std'].append(standard_deviation)\n",
    "            new_df[column+'_median'].append(median)\n",
    "            new_df[column+'_skewness'].append(skewness)\n",
    "            new_df[column+'_kurtosis'].append(kurtosis)\n",
    "\n",
    "            \n",
    "        new_df['pid'].append(pid)\n",
    "        age = np.array(df.loc[df['pid'] == pid].Age)\n",
    "        #print (age[0])\n",
    "        new_df['Age'].append(age[0])\n",
    "        \n",
    "    new_df = pd.DataFrame.from_dict(new_df)\n",
    "    return new_df\n",
    "\n",
    "print (\"Extracting new features from the training data\")\n",
    "\n",
    "new_train_features_imp = new_df(train_features_imp)\n",
    "\n",
    "print (\"###############################\")\n",
    "\n",
    "print (\"Extracting new features from the test data\")\n",
    "new_test_features_imp = new_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = new_train_features_imp.columns.values[(new_train_features_imp.columns.values != 'pid') & (new_train_features_imp.columns.values != 'Time')]\n",
    "\n",
    "X_train= new_train_features_imp[feature_cols]\n",
    "X_test = new_test_features_imp[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 and Task 2 \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "TESTS = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "          'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "          'LABEL_Bilirubin_direct', 'LABEL_EtCO2','LABEL_Sepsis']\n",
    "\n",
    "\n",
    "df_submission = pd.DataFrame(new_test_features_imp.pid.values, columns = ['pid'])\n",
    "\n",
    "\n",
    "for label in tqdm(TESTS):\n",
    "    \n",
    "  \n",
    "    if label == 'LABEL_AST' or label == 'LABEL_Lactate' or label == 'LABEL_Bilirubin_total' or label == 'LABEL_Bilirubin_direct' or label == 'LABEL_TroponinI' or label == 'LABEL_Sepsis':\n",
    "        \n",
    "        y_train_temp = train_labels[label]\n",
    "        model = RandomForestClassifier(criterion = 'entropy', max_features = 'log2', n_estimators = 200, random_state=42)\n",
    "        model.fit(X_train, y_train_temp)\n",
    "        predictions_prob_test = model.predict_proba(X_test)\n",
    "        predict_prob_test = pd.DataFrame(np.ravel(predictions_prob_test[:,1]), columns = [label])\n",
    "        df_submission = pd.concat([df_submission, predict_prob_test], axis = 1, sort = False)\n",
    "         \n",
    "    else:\n",
    "        \n",
    "        y_train_temp = train_labels[label]\n",
    "        model = RandomForestClassifier(criterion = 'entropy', max_features = 'auto', n_estimators = 200, random_state=42)\n",
    "        model.fit(X_train, y_train_temp)\n",
    "        predictions_prob_test = model.predict_proba(X_test)\n",
    "        predict_prob_test = pd.DataFrame(np.ravel(predictions_prob_test[:,1]), columns = [label])\n",
    "        df_submission = pd.concat([df_submission, predict_prob_test], axis = 1, sort = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "\n",
    "VITALS = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "feature_cols = X_train.columns.values[(X_train.columns.values != 'pid') & (X_train.columns.values != 'Time')]\n",
    "\n",
    "X_train = X_train[feature_cols]\n",
    "X_test = X_test[feature_cols]\n",
    "\n",
    "for label in VITALS:\n",
    "\n",
    "    if label == 'LABEL_SpO2':\n",
    "\n",
    "        y_temp = train_labels[label]\n",
    "        reg = LinearRegression().fit(X_train, y_temp) # fitting the data\n",
    "        y_pred = pd.DataFrame(reg.predict(X_test), columns = [label])\n",
    "        df_submission = pd.concat([df_submission, y_pred], axis = 1, sort = False)\n",
    "    \n",
    "    elif:\n",
    "        y_temp = train_labels[label]\n",
    "        rfr = RandomForestRegressor(random_state = 2020, n_estimators = 200).fit(X_train, y_temp) # fitting the data\n",
    "        y_pred = pd.DataFrame(rfr.predict(X_test), columns = [label])\n",
    "        df_submission = pd.concat([df_submission, y_pred], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(r'predictions.csv', index = False, float_format='%.3f')\n",
    "print (\"All done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
